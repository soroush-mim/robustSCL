{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 12:29:07.227803: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "\n",
    "import tensorboard_logger as tb_logger\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from util import TwoCropTransform, AverageMeter\n",
    "from util import adjust_learning_rate, warmup_learning_rate\n",
    "from util import set_optimizer, save_model\n",
    "from networks.resnet_big import SupConResNet,LinearClassifier\n",
    "from losses import SupConLoss\n",
    "from adv_train import PGDCons , PGDConsMulti\n",
    "\n",
    "from main_ce import set_loader\n",
    "from adv_train import PGDAttack\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_loader():\n",
    "    # construct data loader\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='./datasets/',\n",
    "                                        transform=TwoCropTransform(train_transform),\n",
    "                                        download=True)\n",
    "\n",
    "\n",
    "    train_sampler = None\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=8, shuffle=(train_sampler is None),\n",
    "        num_workers=16, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def set_model():\n",
    "    model = SupConResNet(name='resnet18')\n",
    "    criterion = SupConLoss(temperature=0.1)\n",
    "\n",
    "    # enable synchronized Batch Normalization\n",
    "    # if opt.syncBN:\n",
    "    #     model = apex.parallel.convert_syncbn_model(model)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model.encoder = torch.nn.DataParallel(model.encoder,device_ids = [0,1])\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    return model, criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_linear(opt):\n",
    "    model = SupConResNet(name=opt.model)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    classifier = LinearClassifier(name=opt.model, num_classes=opt.n_cls)\n",
    "\n",
    "    ckpt = torch.load(opt.ckpt, map_location='cpu')\n",
    "    state_dict = ckpt['model']\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model.encoder = torch.nn.DataParallel(model.encoder, device_ids = [0,1])\n",
    "        else:\n",
    "            new_state_dict = {}\n",
    "            for k, v in state_dict.items():\n",
    "                k = k.replace(\"module.\", \"\")\n",
    "                new_state_dict[k] = v\n",
    "            state_dict = new_state_dict\n",
    "        model = model.cuda()\n",
    "        classifier = classifier.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    return model, classifier, criterion\n",
    "\n",
    "\n",
    "def set_loader_linear(opt):\n",
    "    # construct data loader\n",
    "    if opt.dataset == 'cifar10':\n",
    "        mean = (0.4914, 0.4822, 0.4465)\n",
    "        std = (0.2023, 0.1994, 0.2010)\n",
    "    elif opt.dataset == 'cifar100':\n",
    "        mean = (0.5071, 0.4867, 0.4408)\n",
    "        std = (0.2675, 0.2565, 0.2761)\n",
    "    else:\n",
    "        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    if opt.dataset == 'cifar10':\n",
    "        train_dataset = datasets.CIFAR10(root=opt.data_folder,\n",
    "                                         transform=train_transform,\n",
    "                                         download=True)\n",
    "        val_dataset = datasets.CIFAR10(root=opt.data_folder,\n",
    "                                       train=False,\n",
    "                                       transform=val_transform)\n",
    "    elif opt.dataset == 'cifar100':\n",
    "        train_dataset = datasets.CIFAR100(root=opt.data_folder,\n",
    "                                          transform=train_transform,\n",
    "                                          download=True)\n",
    "        val_dataset = datasets.CIFAR100(root=opt.data_folder,\n",
    "                                        train=False,\n",
    "                                        transform=val_transform)\n",
    "    else:\n",
    "        raise ValueError(opt.dataset)\n",
    "\n",
    "    train_sampler = None\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=opt.batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=opt.num_workers, pin_memory=True, sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=256, shuffle=False,\n",
    "        num_workers=8, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def set_optimizer(opt, model):\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=opt.learning_rate,\n",
    "                          momentum=opt.momentum,\n",
    "                          weight_decay=opt.weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = set_loader_linear(opt)\n",
    "\n",
    "# build model and criterion\n",
    "model, classifier, criterion = set_model_linear(opt)\n",
    "\n",
    "# build optimizer\n",
    "optimizer = set_optimizer(opt, classifier)\n",
    "\n",
    "\n",
    "test_attack = PGDAttack(model, classifier, eps=8./255., alpha = 2./255., steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader = set_loader()\n",
    "\n",
    "# build model and criterion\n",
    "model, criterion = set_model()\n",
    "\n",
    "# build optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                        lr=0.5,\n",
    "                        momentum=0.9,\n",
    "                        weight_decay=1e-4)\n",
    "                        \n",
    "atk = PGDCons(model, eps=8./255, alpha=2./225, steps=10, random_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchattacks\n",
    "torchattacks.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "atk.set_normalization_used(mean = (0.4914, 0.4822, 0.4465), std = (0.2023, 0.1994, 0.2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images = torch.cat([images[0], images[1]], dim=0)\n",
    "images = images.cuda(non_blocking=True)\n",
    "labels = labels.cuda(non_blocking=True)\n",
    "bsz = labels.shape[0]\n",
    "adv_images = atk(images, labels, loss = criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "adv_images = atk(images, labels, loss = criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6941, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = model(adv_images)\n",
    "f1, f2 = torch.split(features, [bsz, bsz], dim=0) #f1 and f2 -> torch.Size([bsz, 128]\n",
    "features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1) #torch.Size([bsz, 2 (view), 128(feature dim)])\n",
    "loss = criterion(features, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7763, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = model(images)\n",
    "f1, f2 = torch.split(features, [bsz, bsz], dim=0) #f1 and f2 -> torch.Size([bsz, 128]\n",
    "features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1) #torch.Size([bsz, 2 (view), 128(feature dim)])\n",
    "loss = criterion(features, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = model(images)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_atc = PGDConsMulti(model, eps=8./255, alpha=2./225, steps=10, random_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "attacks = multi_atc(images, labels, loss = criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model(images)\n",
    "f1, f2 = torch.split(features, [bsz, bsz], dim=0) #f1 and f2 -> torch.Size([bsz, 128]\n",
    "features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1) #torch.Size([bsz, 2 (view), 128(feature dim)])\n",
    "loss = criterion(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks.append(images)\n",
    "len(attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = torch.cat(attacks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([176, 3, 32, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([176, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = model(attacks)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = torch.split(features, [bsz for i in range(2*pgd_steps + 2)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.4490, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.cat([f.unsqueeze(1) for f in fs], dim=1) #torch.Size([bsz, 2 (view), 128(feature dim)])\n",
    "loss = criterion(features, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 22, 128])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e420fef0df05a076ab926670175cd176585054a9538aeadcfd308c0dc4b041a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
