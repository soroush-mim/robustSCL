{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "from networks.resnet_big import SupConResNet,LinearClassifier\n",
    "from losses import SupConLoss\n",
    "from adv_train import PGDCons , PGDConsMulti\n",
    "\n",
    "from main_ce import set_loader\n",
    "from adv_train import PGDAttack\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from autoattack import AutoAttack\n",
    "torch.cuda.device_count()\n",
    "\n",
    "# AutoAttack.__version__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_linear():\n",
    "    model = SupConResNet(name='resnet18')\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    classifier = LinearClassifier(name='resnet18', num_classes=10)\n",
    "\n",
    "    ckpt = torch.load('save/SupCon/cifar10_models/7,8,9_resnet18_lr_0.1_decay_0.0005_bsz_200_temp_0.07_trial_0eam0.996_cosine/last.pth',\n",
    "    map_location='cpu')\n",
    "    state_dict = ckpt['model']\n",
    "    classifier_state = torch.load('satge2_7,8,9_resnet18_lr_0.1_decay_0.0005_bsz_200_temp_0.07_trial_0eam0.996_cosine.pth', map_location='cpu' )\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            pass\n",
    "            model.encoder = torch.nn.DataParallel(model.encoder, device_ids = [0,1])\n",
    "            print('multi')\n",
    "        else:\n",
    "            new_state_dict = {}\n",
    "            for k, v in state_dict.items():\n",
    "                k = k.replace(\"module.\", \"\")\n",
    "                new_state_dict[k] = v\n",
    "            state_dict = new_state_dict\n",
    "        model = model.cuda()\n",
    "        classifier = classifier.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "        model.load_state_dict(state_dict)\n",
    "        classifier.load_state_dict(classifier_state)\n",
    "    else:\n",
    "        raise KeyError\n",
    "\n",
    "    return model, classifier, criterion\n",
    "\n",
    "\n",
    "def set_loader_linear():\n",
    "\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        # normalize,\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # normalize,\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='./datasets/',\n",
    "                                        transform=train_transform,\n",
    "                                        download=True)\n",
    "    val_dataset = datasets.CIFAR10(root='./datasets/',\n",
    "                                    train=False,\n",
    "                                    transform=val_transform)\n",
    "\n",
    "\n",
    "    train_sampler = None\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=16, shuffle=(train_sampler is None),\n",
    "        num_workers=8, pin_memory=True, sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=256, shuffle=False,\n",
    "        num_workers=8, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def set_optimizer( model):\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=0.1,\n",
    "                          momentum=0.9,\n",
    "                          weight_decay=0.0005)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModel(nn.Module):\n",
    "    \"\"\"Linear classifier\"\"\"\n",
    "    def __init__(self, encoder, linearClassifier):\n",
    "        super(ClassifierModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.linearClassifier = linearClassifier\n",
    "        # self.mu = torch.Tensor([0.4914, 0.4822, 0.4465]).float().view(3, 1, 1).cuda()\n",
    "        # self.sigma = torch.Tensor((0.2023, 0.1994, 0.2010)).float().view(3, 1, 1).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = (x - self.mu) / self.sigma\n",
    "        return self.linearClassifier(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = set_loader_linear()\n",
    "\n",
    "# build model and criterion\n",
    "model, classifier, criterion = set_model_linear()\n",
    "\n",
    "# build optimizer\n",
    "optimizer = set_optimizer(classifier)\n",
    "\n",
    "# test_attack = PGDAttack(model, classifier, eps=8./255., alpha = 2./255., steps=50)\n",
    "\n",
    "CModel = ClassifierModel(model.encoder, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting parameters for standard version\n",
      "using standard version including apgd-ce\n",
      "initial accuracy: 76.73%\n",
      "apgd-ce - 1/16 - 186 out of 500 successfully perturbed\n",
      "apgd-ce - 2/16 - 191 out of 500 successfully perturbed\n",
      "apgd-ce - 3/16 - 182 out of 500 successfully perturbed\n",
      "apgd-ce - 4/16 - 200 out of 500 successfully perturbed\n",
      "apgd-ce - 5/16 - 173 out of 500 successfully perturbed\n",
      "apgd-ce - 6/16 - 170 out of 500 successfully perturbed\n",
      "apgd-ce - 7/16 - 176 out of 500 successfully perturbed\n",
      "apgd-ce - 8/16 - 183 out of 500 successfully perturbed\n",
      "apgd-ce - 9/16 - 193 out of 500 successfully perturbed\n",
      "apgd-ce - 10/16 - 206 out of 500 successfully perturbed\n",
      "apgd-ce - 11/16 - 181 out of 500 successfully perturbed\n",
      "apgd-ce - 12/16 - 186 out of 500 successfully perturbed\n",
      "apgd-ce - 13/16 - 183 out of 500 successfully perturbed\n",
      "apgd-ce - 14/16 - 179 out of 500 successfully perturbed\n",
      "apgd-ce - 15/16 - 182 out of 500 successfully perturbed\n",
      "apgd-ce - 16/16 - 65 out of 173 successfully perturbed\n",
      "robust accuracy after APGD-CE: 48.37% (total time 136.1 s)\n",
      "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 48.37%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = './results'\n",
    "# create save dir\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# load attack    \n",
    "# CModel.eval()\n",
    "CModel.train()\n",
    "adversary = AutoAttack(CModel, norm='Linf', eps=8./255., version='standard', log_path='./log_file.txt')\n",
    "adversary.attacks_to_run = ['apgd-ce']#, 'apgd-t']\n",
    "# adversary.attacks_to_run = ['square']\n",
    "# adversary.square.n_restarts=5\n",
    "# adversary.square.n_queries=10000\n",
    "l = [x for (x, y) in val_loader]\n",
    "x_test = torch.cat(l, 0)\n",
    "l = [y for (x, y) in val_loader]\n",
    "y_test = torch.cat(l, 0)\n",
    "\n",
    "# example of custom version\n",
    "# if version == 'custom':\n",
    "#     adversary.attacks_to_run = ['apgd-ce', 'fab']\n",
    "    # adversary.apgd.n_restarts = 2\n",
    "    # adversary.fab.n_restarts = 2\n",
    "\n",
    "# run attack and save images\n",
    "with torch.no_grad():\n",
    "        adv_complete = adversary.run_standard_evaluation(x_test, y_test,bs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting parameters for standard version\n",
      "using standard version including square\n",
      "initial accuracy: 84.68%\n",
      "square - 1/9 - 63 out of 1000 successfully perturbed\n",
      "square - 2/9 - 58 out of 1000 successfully perturbed\n",
      "square - 3/9 - 61 out of 1000 successfully perturbed\n",
      "square - 4/9 - 59 out of 1000 successfully perturbed\n",
      "square - 5/9 - 62 out of 1000 successfully perturbed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-65a09c987c8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# run attack and save images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0madv_complete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_standard_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/data2/antispoofing/codes/Soroush/robustSCL/venv/lib/python3.8/site-packages/autoattack/autoattack.py\u001b[0m in \u001b[0;36mrun_standard_evaluation\u001b[0;34m(self, x_orig, y_orig, bs, return_labels)\u001b[0m\n\u001b[1;32m    167\u001b[0m                         \u001b[0;31m# square\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                         \u001b[0madv_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0mattack\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'apgd-t'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data2/antispoofing/codes/Soroush/robustSCL/venv/lib/python3.8/site-packages/autoattack/square.py\u001b[0m in \u001b[0;36mperturb\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    593\u001b[0m                 \u001b[0my_to_fool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_to_fool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_single_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_to_fool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_to_fool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0moutput_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_curr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data2/antispoofing/codes/Soroush/robustSCL/venv/lib/python3.8/site-packages/autoattack/square.py\u001b[0m in \u001b[0;36mattack_single_run\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    267\u001b[0m                     \u001b[0mx_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                     \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmargin_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_curr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0;31m# update loss if new loss is better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data2/antispoofing/codes/Soroush/robustSCL/venv/lib/python3.8/site-packages/autoattack/square.py\u001b[0m in \u001b[0;36mmargin_and_loss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mxent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0my_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0my_others\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "adversary = AutoAttack(CModel, norm='Linf', eps=8./255., version='standard', log_path='./log_file.txt')\n",
    "# adversary.attacks_to_run = ['apgd-ce']\n",
    "adversary.attacks_to_run = ['square']\n",
    "adversary.square.n_restarts=5\n",
    "adversary.square.n_queries=10000\n",
    "l = [x for (x, y) in val_loader]\n",
    "x_test = torch.cat(l, 0)\n",
    "l = [y for (x, y) in val_loader]\n",
    "y_test = torch.cat(l, 0)\n",
    "\n",
    "# example of custom version\n",
    "# if version == 'custom':\n",
    "#     adversary.attacks_to_run = ['apgd-ce', 'fab']\n",
    "    # adversary.apgd.n_restarts = 2\n",
    "    # adversary.fab.n_restarts = 2\n",
    "\n",
    "# run attack and save images\n",
    "with torch.no_grad():\n",
    "        adv_complete = adversary.run_standard_evaluation(x_test, y_test,bs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'benchmark' from 'robustbench.eval' (/mnt/data2/antispoofing/codes/Soroush/robustSCL/venv/lib/python3.8/site-packages/robustbench/eval.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b311b9c5f593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrobustbench\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'benchmark' from 'robustbench.eval' (/mnt/data2/antispoofing/codes/Soroush/robustSCL/venv/lib/python3.8/site-packages/robustbench/eval.py)"
     ]
    }
   ],
   "source": [
    "from robustbench.eval import benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 84 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        images = images.cuda(non_blocking=True)\n",
    "        labels = labels.cuda(non_blocking=True)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = CModel(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attack.set_normalization_used(mean = (0.4914, 0.4822, 0.4465), std = (0.2023, 0.1994, 0.2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images = images.cuda(non_blocking=True)\n",
    "labels = labels.cuda(non_blocking=True)\n",
    "bsz = labels.shape[0]\n",
    "adv_images = test_attack(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3043, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    features = model.encoder(images)\n",
    "output = classifier(features.detach())\n",
    "loss = criterion(output, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3116, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    features = model.encoder(adv_images)\n",
    "output = classifier(features.detach())\n",
    "loss = criterion(output, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7145, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = CModel(images)\n",
    "loss = criterion(output, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7714, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = CModel(adv_images)\n",
    "loss = criterion(output, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7763, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = model(images)\n",
    "f1, f2 = torch.split(features, [bsz, bsz], dim=0) #f1 and f2 -> torch.Size([bsz, 128]\n",
    "features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1) #torch.Size([bsz, 2 (view), 128(feature dim)])\n",
    "loss = criterion(features, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = model(images)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_atc = PGDConsMulti(model, eps=8./255, alpha=2./225, steps=10, random_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "attacks = multi_atc(images, labels, loss = criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model(images)\n",
    "f1, f2 = torch.split(features, [bsz, bsz], dim=0) #f1 and f2 -> torch.Size([bsz, 128]\n",
    "features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1) #torch.Size([bsz, 2 (view), 128(feature dim)])\n",
    "loss = criterion(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks.append(images)\n",
    "len(attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = torch.cat(attacks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([176, 3, 32, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([176, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = model(attacks)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = torch.split(features, [bsz for i in range(2*pgd_steps + 2)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.4490, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.cat([f.unsqueeze(1) for f in fs], dim=1) #torch.Size([bsz, 2 (view), 128(feature dim)])\n",
    "loss = criterion(features, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 22, 128])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e420fef0df05a076ab926670175cd176585054a9538aeadcfd308c0dc4b041a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
