{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "from networks.resnet_big import SupConResNet,LinearClassifier\n",
    "from losses import SupConLoss\n",
    "from adv_train import PGDCons , PGDConsMulti\n",
    "\n",
    "from main_ce import set_loader\n",
    "from adv_train import PGDAttack\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from autoattack import AutoAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_linear():\n",
    "    model = SupConResNet(name='resnet18')\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    classifier = LinearClassifier(name='resnet18', num_classes=10)\n",
    "\n",
    "    ckpt = torch.load('save/SupCon/cifar10_models/SupCon_cifar10_resnet18_lr_0.1_decay_0.0005_bsz_300_temp_0.07_trial_0,_pgdMultiTrue_pgd_train_steps10_normalizeout_cosine_warm/last.pth',\n",
    "    map_location='cpu')\n",
    "    state_dict = ckpt['model']\n",
    "    classifier_state = torch.load('classifier_trades_NormalizeOut_bsz256.pth', map_location='cpu' )\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model.encoder = torch.nn.DataParallel(model.encoder, device_ids = [0,1])\n",
    "        else:\n",
    "            new_state_dict = {}\n",
    "            for k, v in state_dict.items():\n",
    "                k = k.replace(\"module.\", \"\")\n",
    "                new_state_dict[k] = v\n",
    "            state_dict = new_state_dict\n",
    "        model = model.cuda()\n",
    "        classifier = classifier.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "\n",
    "        model.load_state_dict(state_dict)\n",
    "        classifier.load_state_dict(classifier_state)\n",
    "\n",
    "    return model, classifier, criterion\n",
    "\n",
    "\n",
    "def set_loader_linear():\n",
    "\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        # normalize,\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # normalize,\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='./datasets/',\n",
    "                                        transform=train_transform,\n",
    "                                        download=True)\n",
    "    val_dataset = datasets.CIFAR10(root='./datasets/',\n",
    "                                    train=False,\n",
    "                                    transform=val_transform)\n",
    "\n",
    "\n",
    "    train_sampler = None\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=16, shuffle=(train_sampler is None),\n",
    "        num_workers=8, pin_memory=True, sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=1000, shuffle=False,\n",
    "        num_workers=8, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def set_optimizer( model):\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=0.1,\n",
    "                          momentum=0.9,\n",
    "                          weight_decay=0.0005)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModel(nn.Module):\n",
    "    \"\"\"Linear classifier\"\"\"\n",
    "    def __init__(self, encoder, linearClassifier):\n",
    "        super(ClassifierModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.linearClassifier = linearClassifier\n",
    "        self.mu = torch.Tensor([0.4914, 0.4822, 0.4465]).float().view(3, 1, 1).cuda()\n",
    "        self.sigma = torch.Tensor((0.2023, 0.1994, 0.2010)).float().view(3, 1, 1).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x - self.mu) / self.sigma\n",
    "        return self.linearClassifier(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = set_loader_linear()\n",
    "\n",
    "# build model and criterion\n",
    "model, classifier, criterion = set_model_linear()\n",
    "\n",
    "# build optimizer\n",
    "optimizer = set_optimizer(classifier)\n",
    "\n",
    "# test_attack = PGDAttack(model, classifier, eps=8./255., alpha = 2./255., steps=50)\n",
    "\n",
    "CModel = ClassifierModel(model.encoder, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting parameters for standard version\n",
      "using standard version including apgd-ce\n",
      "initial accuracy: 79.16%\n",
      "apgd-ce - 1/16 - 195 out of 500 successfully perturbed\n",
      "apgd-ce - 2/16 - 216 out of 500 successfully perturbed\n",
      "apgd-ce - 3/16 - 208 out of 500 successfully perturbed\n",
      "apgd-ce - 4/16 - 206 out of 500 successfully perturbed\n",
      "apgd-ce - 5/16 - 209 out of 500 successfully perturbed\n",
      "apgd-ce - 6/16 - 195 out of 500 successfully perturbed\n",
      "apgd-ce - 7/16 - 192 out of 500 successfully perturbed\n",
      "apgd-ce - 8/16 - 195 out of 500 successfully perturbed\n",
      "apgd-ce - 9/16 - 222 out of 500 successfully perturbed\n",
      "apgd-ce - 10/16 - 208 out of 500 successfully perturbed\n",
      "apgd-ce - 11/16 - 211 out of 500 successfully perturbed\n",
      "apgd-ce - 12/16 - 213 out of 500 successfully perturbed\n",
      "apgd-ce - 13/16 - 205 out of 500 successfully perturbed\n",
      "apgd-ce - 14/16 - 212 out of 500 successfully perturbed\n",
      "apgd-ce - 15/16 - 202 out of 500 successfully perturbed\n",
      "apgd-ce - 16/16 - 170 out of 416 successfully perturbed\n",
      "robust accuracy after APGD-CE: 46.57% (total time 90.8 s)\n",
      "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 46.57%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = './results'\n",
    "# create save dir\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# load attack    \n",
    "\n",
    "adversary = AutoAttack(CModel, norm='Linf', eps=8./255., version='standard', log_path='./log_file.txt')\n",
    "adversary.attacks_to_run = ['apgd-ce']\n",
    "l = [x for (x, y) in val_loader]\n",
    "x_test = torch.cat(l, 0)\n",
    "l = [y for (x, y) in val_loader]\n",
    "y_test = torch.cat(l, 0)\n",
    "\n",
    "# example of custom version\n",
    "# if version == 'custom':\n",
    "#     adversary.attacks_to_run = ['apgd-ce', 'fab']\n",
    "    # adversary.apgd.n_restarts = 2\n",
    "    # adversary.fab.n_restarts = 2\n",
    "\n",
    "# run attack and save images\n",
    "with torch.no_grad():\n",
    "        adv_complete = adversary.run_standard_evaluation(x_test, y_test,bs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 84 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        images = images.cuda(non_blocking=True)\n",
    "        labels = labels.cuda(non_blocking=True)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = CModel(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attack.set_normalization_used(mean = (0.4914, 0.4822, 0.4465), std = (0.2023, 0.1994, 0.2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images = images.cuda(non_blocking=True)\n",
    "labels = labels.cuda(non_blocking=True)\n",
    "bsz = labels.shape[0]\n",
    "adv_images = test_attack(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3043, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    features = model.encoder(images)\n",
    "output = classifier(features.detach())\n",
    "loss = criterion(output, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3116, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    features = model.encoder(adv_images)\n",
    "output = classifier(features.detach())\n",
    "loss = criterion(output, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7145, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = CModel(images)\n",
    "loss = criterion(output, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7714, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = CModel(adv_images)\n",
    "loss = criterion(output, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7763, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = model(images)\n",
    "f1, f2 = torch.split(features, [bsz, bsz], dim=0) #f1 and f2 -> torch.Size([bsz, 128]\n",
    "features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1) #torch.Size([bsz, 2 (view), 128(feature dim)])\n",
    "loss = criterion(features, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = model(images)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_atc = PGDConsMulti(model, eps=8./255, alpha=2./225, steps=10, random_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "attacks = multi_atc(images, labels, loss = criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model(images)\n",
    "f1, f2 = torch.split(features, [bsz, bsz], dim=0) #f1 and f2 -> torch.Size([bsz, 128]\n",
    "features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1) #torch.Size([bsz, 2 (view), 128(feature dim)])\n",
    "loss = criterion(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks.append(images)\n",
    "len(attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = torch.cat(attacks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([176, 3, 32, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([176, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = model(attacks)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = torch.split(features, [bsz for i in range(2*pgd_steps + 2)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.4490, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.cat([f.unsqueeze(1) for f in fs], dim=1) #torch.Size([bsz, 2 (view), 128(feature dim)])\n",
    "loss = criterion(features, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 22, 128])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e420fef0df05a076ab926670175cd176585054a9538aeadcfd308c0dc4b041a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
